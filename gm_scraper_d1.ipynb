{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPWr0g1LQ9QpMvRMABfka0+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/roy-sub/Automated-Google-Map-Scrapper/blob/main/gm_scraper_d1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Installing Necessary Libraries and Files**"
      ],
      "metadata": {
        "id": "R0GZG-jKFtQh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3TCz6m6TE5rl"
      },
      "outputs": [],
      "source": [
        "! pip -q install langchain openai tiktoken cohere\n",
        "! gdown --id 1NLsQzhzwcOqYvrVHpzpvD1-u1840rzFO # constant.py"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Provide OpenAI Credentials**"
      ],
      "metadata": {
        "id": "0iF_CRQnIJJv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] =\"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\""
      ],
      "metadata": {
        "id": "JDJJKYXyIIFI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Primary Script : To get relevant Google Map Searches**"
      ],
      "metadata": {
        "id": "ueNy_T3eGoS-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary modules and classes\n",
        "\n",
        "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
        "from langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from constants import SEARCH_TERM_TEMPLATE_STRING, SEARCH_LOCATION_TEMPLATE_STRING\n",
        "\n",
        "def get_gm_search(search_term, search_location):\n",
        "\n",
        "  try:\n",
        "\n",
        "    # Initialize output parser, format instructions, and language model\n",
        "\n",
        "    output_parser = CommaSeparatedListOutputParser()\n",
        "\n",
        "    format_instructions = output_parser.get_format_instructions()\n",
        "\n",
        "    llm = ChatOpenAI(temperature=0.0) # model_name=\"text-davinci-003\"\n",
        "\n",
        "    # Operation I : Get Related Search Terms\n",
        "\n",
        "    search_term_prompt = ChatPromptTemplate(\n",
        "        messages=[\n",
        "            HumanMessagePromptTemplate.from_template(SEARCH_TERM_TEMPLATE_STRING)\n",
        "        ],\n",
        "        input_variables=[\"industry_name\"],\n",
        "        partial_variables={\"format_instructions\": format_instructions}\n",
        "    )\n",
        "\n",
        "    search_term_messages_for_list_prompt = search_term_prompt.format_messages(industry_name=search_term,\n",
        "                                    format_instructions=format_instructions)\n",
        "\n",
        "    search_term_output = llm(search_term_messages_for_list_prompt)\n",
        "\n",
        "    related_terms = output_parser.parse(search_term_output.content)\n",
        "\n",
        "    # Operation II : Get Nearby Locations\n",
        "\n",
        "    search_location_prompt = ChatPromptTemplate(\n",
        "        messages=[\n",
        "            HumanMessagePromptTemplate.from_template(SEARCH_LOCATION_TEMPLATE_STRING)\n",
        "        ],\n",
        "        input_variables=[\"location_name\"],\n",
        "        partial_variables={\"format_instructions\": format_instructions}\n",
        "    )\n",
        "\n",
        "    search_location_messages_for_list_prompt = search_location_prompt.format_messages(location_name=search_location,\n",
        "                                    format_instructions=format_instructions)\n",
        "\n",
        "    search_location_output = llm(search_location_messages_for_list_prompt)\n",
        "\n",
        "    nearby_locations = output_parser.parse(search_location_output.content)\n",
        "\n",
        "    # Operation III : Get Relevant Google Map Searches\n",
        "\n",
        "    gm_search = [f\"{related_terms[i].capitalize()} in {nearby_locations[j].capitalize()}\" for i in range(len(related_terms)) for j in range(len(nearby_locations))]\n",
        "\n",
        "    return gm_search\n",
        "\n",
        "  except Exception as e:\n",
        "\n",
        "    print(f\"An error occurred: {e}\")\n",
        "\n",
        "    return None"
      ],
      "metadata": {
        "id": "02gh6vPjF6xy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Testing**"
      ],
      "metadata": {
        "id": "HoyitNs4JXSI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **User Input**\n",
        "\n",
        "search_term = 'Indian Restaurants' #@param {type:'string'}\n",
        "search_location = 'London' #@param {type:'string'}\n",
        "\n",
        "gm_search = get_gm_search(search_term, search_location)\n",
        "\n",
        "gm_search"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "WNeieysKHIp4",
        "outputId": "15d8d8ef-6909-42e4-9de2-4dc25bd4788c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Curry houses in Oxford',\n",
              " 'Curry houses in Cambridge',\n",
              " 'Curry houses in Brighton',\n",
              " 'Curry houses in Bristol',\n",
              " 'Curry houses in Reading',\n",
              " 'Curry houses in Southampton',\n",
              " 'Curry houses in Birmingham',\n",
              " 'Curry houses in Manchester',\n",
              " 'Curry houses in Liverpool',\n",
              " 'Curry houses in Cardiff',\n",
              " 'Tandoori restaurants in Oxford',\n",
              " 'Tandoori restaurants in Cambridge',\n",
              " 'Tandoori restaurants in Brighton',\n",
              " 'Tandoori restaurants in Bristol',\n",
              " 'Tandoori restaurants in Reading',\n",
              " 'Tandoori restaurants in Southampton',\n",
              " 'Tandoori restaurants in Birmingham',\n",
              " 'Tandoori restaurants in Manchester',\n",
              " 'Tandoori restaurants in Liverpool',\n",
              " 'Tandoori restaurants in Cardiff',\n",
              " 'Biryani restaurants in Oxford',\n",
              " 'Biryani restaurants in Cambridge',\n",
              " 'Biryani restaurants in Brighton',\n",
              " 'Biryani restaurants in Bristol',\n",
              " 'Biryani restaurants in Reading',\n",
              " 'Biryani restaurants in Southampton',\n",
              " 'Biryani restaurants in Birmingham',\n",
              " 'Biryani restaurants in Manchester',\n",
              " 'Biryani restaurants in Liverpool',\n",
              " 'Biryani restaurants in Cardiff',\n",
              " 'South indian restaurants in Oxford',\n",
              " 'South indian restaurants in Cambridge',\n",
              " 'South indian restaurants in Brighton',\n",
              " 'South indian restaurants in Bristol',\n",
              " 'South indian restaurants in Reading',\n",
              " 'South indian restaurants in Southampton',\n",
              " 'South indian restaurants in Birmingham',\n",
              " 'South indian restaurants in Manchester',\n",
              " 'South indian restaurants in Liverpool',\n",
              " 'South indian restaurants in Cardiff',\n",
              " 'North indian restaurants in Oxford',\n",
              " 'North indian restaurants in Cambridge',\n",
              " 'North indian restaurants in Brighton',\n",
              " 'North indian restaurants in Bristol',\n",
              " 'North indian restaurants in Reading',\n",
              " 'North indian restaurants in Southampton',\n",
              " 'North indian restaurants in Birmingham',\n",
              " 'North indian restaurants in Manchester',\n",
              " 'North indian restaurants in Liverpool',\n",
              " 'North indian restaurants in Cardiff',\n",
              " 'Street food stalls in Oxford',\n",
              " 'Street food stalls in Cambridge',\n",
              " 'Street food stalls in Brighton',\n",
              " 'Street food stalls in Bristol',\n",
              " 'Street food stalls in Reading',\n",
              " 'Street food stalls in Southampton',\n",
              " 'Street food stalls in Birmingham',\n",
              " 'Street food stalls in Manchester',\n",
              " 'Street food stalls in Liverpool',\n",
              " 'Street food stalls in Cardiff']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Future Updates Information**\n",
        "\n",
        "* We are currently utilizing the `text-davinci-003` model from `OpenAI` for our project. While this model is cost-effective at $0.02 per 1000 tokens, it is not entirely `FREE`. Our decision to use this model as a baseline is strategic, as it allows us to focus on developing the next milestones without dedicating excessive time to selecting the ideal model.\n",
        "Additionally, transitioning to a more suitable model for our use-case is straightforward, requiring just a few lines of script updates. Moving forward, I will explore various open-source models to achieve similar, if not better, accuracy and latency without incurring any costs i.e. `FREE`. This parallel exploration will enable us to enhance our project's performance while ensuring cost efficiency.\n",
        "\n",
        "* Furthermore, while LLM models are powerful, they are still susceptible to hallucinations. There may be rare scenarios where the `related_terms` and `nearby_locations` generated are not as expected in terms of `format` or `correctness`. Therefore, I recommend implementing a validator script to verify these results after they are generated. It is important to note that while this step is necessary, it may increase latency and potentially lead to a poorer user experience. As a result, I have not implemented it in our current version. I would appreciate your feedback on how we should proceed with this matter.\n",
        "\n",
        "* Lastly, I'd like to draw attention to our error handling approach at the end of our script. While errors are highly unlikely, it is not a standard practice in application development to simply print them. It is recommended that in such cases, we log the error in our database for e.g., `Azur` along with the `client_id, date_time and process_id`. These parameters will become more clear once the application reaches `milestone III`. As we progress towards `milestone III`, I will request your Azure credentials to implement this `logging mechanism`. Your feedback on this approach is also appreciated."
      ],
      "metadata": {
        "id": "7seorxqsOpTf"
      }
    }
  ]
}